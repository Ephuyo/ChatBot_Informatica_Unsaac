{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ephuyo/ChatBot_Informatica_Unsaac/blob/main/YachayBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Automatización de Consultas en la Escuela Profesional de Ingeniería Informática y de Sistemas de la UNSAAC mediante la Implementación de un Chatbot para Docentes y Estudiantes:\n",
        "\n",
        "Este proyecto tiene como objetivo implementar un chatbot que permita automatizar y agilizar las consultas realizadas por docentes y estudiantes en la Escuela Profesional de Ingeniería Informática y de Sistemas de la UNSAAC. A través de esta solución innovadora, se busca mejorar la accesibilidad a la información relevante, proporcionando respuestas precisas sobre horarios, cursos, requisitos académicos y otras consultas frecuentes. El chatbot se convertirá en una herramienta eficiente para resolver dudas y brindar orientación, optimizando la experiencia de todos los usuarios involucrados.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rIMdao7das4x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Integrantes:\n",
        "\n",
        "* PHUYO HUAMAN EDSON LEONID          \n",
        "* CABRERA MEJIA CRISTIAN ANDY\t\t     \n",
        "* ZAPANA FLORES GEORGE ALEXANDER\t   \n",
        "* SANDI MAMANI ALEX\t                 "
      ],
      "metadata": {
        "id": "9da8tLBoc7SX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Librerias"
      ],
      "metadata": {
        "id": "JS0-cNX0ebnI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Instalacion e importacion de librerias"
      ],
      "metadata": {
        "id": "hEaiVEAwer-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar la biblioteca 'unidecode' para realizar la transliteración de caracteres Unicode a caracteres ASCII\n",
        "!pip install unidecode"
      ],
      "metadata": {
        "id": "yj6lcWbPa2Mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------Importar las bibliotecas necesarias----------------------------------------------------------------------\n",
        "# Para manejar archivos JSON\n",
        "import json\n",
        "# Biblioteca de procesamiento de lenguaje natural\n",
        "import nltk\n",
        "# Para remover acentos y caracteres especiales de texto\n",
        "import unidecode\n",
        "# Biblioteca de procesamiento de lenguaje natural avanzado\n",
        "import spacy\n",
        "# Función para tokenizar palabras\n",
        "from nltk.tokenize import word_tokenize\n",
        "# Lista de palabras detenidas (stop words)\n",
        "from nltk.corpus import stopwords\n",
        "# Para crear vectores TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Para calcular similitud de coseno\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ],
      "metadata": {
        "id": "zLYuGR9JQZI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargar los recursos necesarios de NLTK\n",
        "nltk.download('punkt')  # Descargar el tokenizador de NLTK\n",
        "nltk.download('stopwords')  # Descargar la lista de stop words en español"
      ],
      "metadata": {
        "id": "MJdDPzgdQ9Ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Actualiza la biblioteca 'spacy' a la última versión disponible\n",
        "!pip install -U spacy\n",
        "\n",
        "# Descarga el modelo de procesamiento de lenguaje natural en español (\"es_core_news_sm\") de spaCy\n",
        "!python -m spacy download es_core_news_sm"
      ],
      "metadata": {
        "id": "7l9v2Zx_bQIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el modelo de lenguaje en español de spaCy\n",
        "nlp = spacy.load('es_core_news_sm')"
      ],
      "metadata": {
        "id": "BZ8Yd-_bRNrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## cargar el corpus"
      ],
      "metadata": {
        "id": "GtUj5PmvfM4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el corpus desde un archivo JSON\n",
        "with open('corpus.json', 'r', encoding='utf-8') as archivo:\n",
        "    corpus = json.load(archivo)"
      ],
      "metadata": {
        "id": "HLXwz-r-Rhcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir las palabras detenidas (stop words) en español\n",
        "palabras_detenidas = set(stopwords.words('spanish'))"
      ],
      "metadata": {
        "id": "__QOWfc_RkkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modulo Preprocesar el texto"
      ],
      "metadata": {
        "id": "obSKY4-vfUPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocesar_texto(texto):\n",
        "    # Procesar el texto con el modelo de spaCy\n",
        "    doc = nlp(texto)\n",
        "\n",
        "    # Filtrar los tokens basados en ciertas propiedades\n",
        "    tokens_filtrados = [\n",
        "        token.lemma_ for token in doc\n",
        "        if not token.is_punct             # No es un signo de puntuación\n",
        "        and not token.is_space            # No es un espacio en blanco\n",
        "        and not token.is_stop             # No es una palabra de parada (palabra común que se suele filtrar en el procesamiento de lenguaje)\n",
        "        and not token.is_digit            # No es un dígito\n",
        "        and not token.like_num            # No se parece a un número (puede ser una combinación de dígitos y letras)\n",
        "    ]\n",
        "\n",
        "    # Unir los tokens filtrados en una cadena de texto\n",
        "    return ' '.join(tokens_filtrados)\n"
      ],
      "metadata": {
        "id": "_JvzFlZOXzIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vectorizacion del texto"
      ],
      "metadata": {
        "id": "0QLBK1F-fovY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crear_vectores_tfidf(corpus):\n",
        "    # Crear una lista para almacenar todas las respuestas del corpus\n",
        "    todas_las_respuestas = []\n",
        "\n",
        "    # Recorrer cada sección en el corpus y extender la lista con los patrones de respuesta\n",
        "    for seccion in corpus.values():\n",
        "        todas_las_respuestas.extend(seccion['patrones'])\n",
        "\n",
        "    # Crear un vectorizador TF-IDF con el preprocesamiento de texto definido anteriormente\n",
        "    vectorizador = TfidfVectorizer(preprocessor=preprocesar_texto)\n",
        "\n",
        "    # Transformar las respuestas en una matriz TF-IDF utilizando el vectorizador\n",
        "    matriz_tfidf = vectorizador.fit_transform(todas_las_respuestas)\n",
        "\n",
        "    # Devolver el vectorizador y la matriz TF-IDF resultante\n",
        "    return vectorizador, matriz_tfidf"
      ],
      "metadata": {
        "id": "sy6yfo-AX95c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modulo para realizar  las similitudes de texto"
      ],
      "metadata": {
        "id": "EdbdVlCffy4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from unidecode import unidecode\n",
        "\n",
        "def buscar_patrones_similares(entrada_usuario, vectorizador, matriz_tfidf, corpus):\n",
        "    # Preprocesar la entrada del usuario utilizando la función preprocesar_texto definida anteriormente\n",
        "    entrada_usuario_preprocesada = preprocesar_texto(entrada_usuario)\n",
        "\n",
        "    # Transformar la entrada del usuario en un vector TF-IDF utilizando el vectorizador\n",
        "    vector_entrada = vectorizador.transform([entrada_usuario_preprocesada])\n",
        "\n",
        "    # Calcular las puntuaciones de similitud coseno entre el vector de entrada y la matriz TF-IDF\n",
        "    puntuaciones_similitud = cosine_similarity(vector_entrada, matriz_tfidf)\n",
        "\n",
        "    # Obtener los índices de las respuestas más similares en orden descendente de similitud\n",
        "    indices_mas_similares = puntuaciones_similitud.argsort()[0, ::-1]\n",
        "\n",
        "    # Inicializar una lista para almacenar las respuestas relevantes\n",
        "    respuestas = []\n",
        "\n",
        "    # Iterar a través de los índices de respuestas más similares\n",
        "    for indice in indices_mas_similares:\n",
        "        similitud = puntuaciones_similitud[0, indice]\n",
        "        if similitud >= 0.2:\n",
        "            patrones = []\n",
        "\n",
        "            # Extender la lista de patrones con los patrones de todas las secciones en el corpus\n",
        "            for seccion in corpus.values():\n",
        "                patrones.extend(seccion['patrones'])\n",
        "\n",
        "            # Obtener el patrón similar basado en el índice actual\n",
        "            patron_similar = patrones[indice].lower()\n",
        "\n",
        "            # Convertir el patrón similar a una forma ASCII normalizada (quitar acentos)\n",
        "            patron_similar = unidecode(patron_similar)\n",
        "\n",
        "            # Buscar el patrón similar en las secciones del corpus y obtener las respuestas correspondientes\n",
        "            for clave, valor in corpus.items():\n",
        "                for patron in valor['patrones']:\n",
        "                    if unidecode(patron.lower()) == patron_similar:\n",
        "                        respuestas = valor['respuestas']\n",
        "                        break\n",
        "            break\n",
        "\n",
        "    return respuestas\n"
      ],
      "metadata": {
        "id": "NRnrnrIXYKvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "LqZE3RxikcUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#saludos"
      ],
      "metadata": {
        "id": "YOavNUMDgRkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SALUDOS_INPUTS = (\"hola\",\"buenas\", \"saludos\", \"qué tal\", \"hey\", \"buenos dias\", \"Buenos dias\", \"Buenas\", \"buenas\", \"hola, que tal?\", \"como estas?\")\n",
        "SALUDOS_OUTPUTS = [\"Hola\", \"Hola, ¿Cómo te puedo ayudar?\", \"Hola, encantado de hablar contigo\",\"¿Hola, en que puedo ayudarte?\"]\n",
        "\n",
        "def saludos(sentence):\n",
        "  for word in sentence.split():\n",
        "    if word.lower() in SALUDOS_INPUTS:\n",
        "      return random.choice(SALUDOS_OUTPUTS)"
      ],
      "metadata": {
        "id": "fT7tmYKDibvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#programa principal"
      ],
      "metadata": {
        "id": "15RUVjBVgKkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chat():\n",
        "    print(\"\\n=====================================================================================================================\")\n",
        "    print(\"\\n************************* ¡BIENVENIDO AL CHATBOT DE LA ESCUELA DE INGENIERÍA INFORMÁTICA! ***************************\")\n",
        "    print(\"************************************************** ¡YACHAYBOT! ******************************************************\")\n",
        "    print(\"\\n=====================================================================================================================\\n\")\n",
        "    print(\" Puedes escribir 'salir' en cualquier momento para terminar.\\n\")\n",
        "\n",
        "    vectorizador, matriz_tfidf = crear_vectores_tfidf(corpus)\n",
        "\n",
        "    while True:\n",
        "        entrada_usuario = input(\"+ Tú: \")\n",
        "        print()\n",
        "        r = saludos(entrada_usuario.lower())\n",
        "\n",
        "        if entrada_usuario.lower() in ['salir', 'adiós', 'chao', 'cerrar','adios','chau', 'hasta pronto','gracias', 'salir','ok']:\n",
        "            print(\">> YachayBot: ¡Hasta luego!\")\n",
        "            break\n",
        "\n",
        "        respuestas = buscar_patrones_similares(entrada_usuario, vectorizador, matriz_tfidf, corpus)\n",
        "        if (r != None):\n",
        "          print(\">> YachayBot: \" + r)\n",
        "          print(\"\")\n",
        "        else:\n",
        "            if not respuestas:\n",
        "              print(\">> YachayBot: Lo siento, no entiendo tu pregunta.\\n\")\n",
        "            else:\n",
        "                for respuesta in respuestas:\n",
        "                    print(\">> YachayBot:\", respuesta)\n",
        "                print(\"\")\n",
        "\n",
        "chat()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkS34lM0R704",
        "outputId": "0112d01d-e0a5-436e-f079-59947588d94e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=====================================================================================================================\n",
            "\n",
            "************************* ¡BIENVENIDO AL CHATBOT DE LA ESCUELA DE INGENIERÍA INFORMÁTICA! ***************************\n",
            "************************************************** ¡YACHAYBOT! ******************************************************\n",
            "\n",
            "=====================================================================================================================\n",
            "\n",
            " Puedes escribir 'salir' en cualquier momento para terminar.\n",
            "\n",
            "+ Tú: hola\n",
            "\n",
            ">> YachayBot: Hola, ¿Cómo te puedo ayudar?\n",
            "\n",
            "+ Tú: uiero saber los requitos para optar el titulo univeristario\n",
            "\n",
            ">> YachayBot: Para optar al título profesional mediante la modalidad de sustentación de tesis, se deben cumplir los siguientes requisitos:\n",
            ">> YachayBot: - Enviar una solicitud dirigida al rector de la universidad a través del trámite virtual establecido.\n",
            ">> YachayBot: - Adjuntar una fotocopia vigente del DNI ampliada a color.\n",
            ">> YachayBot: - Adjuntar una fotocopia del diploma de grado académico a color.\n",
            ">> YachayBot: - Incluir una fotocopia del certificado de estudios.\n",
            ">> YachayBot: - Presentar certificados de antecedentes penales y judiciales.\n",
            ">> YachayBot: - Realizar el pago de los derechos correspondientes por el título profesional en modalidad de sustentación de tesis (434 soles).\n",
            ">> YachayBot: Nota: Todos los documentos deben ser presentados en la mesa de partes de la facultad, utilizando un folder de color granate guinda.\n",
            "\n",
            "+ Tú: y como puedo obtener el certificado de estudios\n",
            "\n",
            ">> YachayBot: Para obtener una constancia de estudios, es necesario:\n",
            ">> YachayBot: - Presentar el recibo de pago correspondiente.\n",
            ">> YachayBot: - Proporcionar la ficha de seguimiento actual.\n",
            ">> YachayBot: - Mostrar la constancia de matrícula vigente.\n",
            "\n",
            "+ Tú: ok\n",
            "\n",
            ">> YachayBot: ¡Hasta luego!\n"
          ]
        }
      ]
    }
  ]
}